# VoxBot-Ai

<p align="center">
 <a href="https://github.com/Whitecat18/VoxBot-Ai"><img src="https://raw.githubusercontent.com/Whitecat18/VoxBot-Ai/main/VoxBot/img-demo/VoxBot.jpeg" height=250/> 
  </p>
  
VoxBoT . An Ai that converts Text to speech using advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output. 

VoxBot Model Documentation -> <a href="https://github.com/Whitecat18/VoxBot-Ai/blob/main/VoxBot%20Model%20Mechanism.pdf" > Click Here </a>

  Model automated by <a href="https://github.com/Whitecat18/" > smukx </a>
## Beta-Release .

Colab Version  ‚úÖ

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1yxIAUt7-4p41hk1CTV0N4CwiwGKCFfzN?usp=sharing)

### Supported Languages

| Language | Status |
| --- | :---: |
| English (en) | ‚úÖ |

  
## Technologies Used
 
  **Transformer-based model**: voxbot uses a transformer-based model, which is a
neural network architecture that is known for its ability to learn long-range
dependencies. This makes it well-suited for tasks such as text-to-audio
generation, where the model needs to understand the meaning of the text and
how it should be pronounced.
  
  **Massive dataset of audio and text:** voxbot is trained on a massive dataset of audio
and text. This dataset includes audio recordings of people speaking in different
languages, as well as text transcripts of those recordings. The model learns to
generate audio that is similar to the audio in the training dataset.
  
  **Natural language processing**: voxbot uses natural language processing (NLP)
techniques to understand the meaning of the input text.
  
  **Speech synthesis:** voxbot uses speech synthesis techniques to generate the
output audio.
  
  **Machine learning:** voxbot uses machine learning techniques to improve its
performance over time.
  
  
## üôè Resources 

- [nanoGPT](https://github.com/karpathy/nanoGPT) for a dead-simple and blazing fast implementation of GPT-style models
- [Bark](https://github.com/suno-ai) for audio convertion and standard outputs in python 
- [EnCodec](https://github.com/facebookresearch/encodec) for a state-of-the-art implementation of a fantastic audio codec
- [AudioLM](https://github.com/lucidrains/audiolm-pytorch) for related training and inference code
- [Vall-E](https://arxiv.org/abs/2301.02111), [AudioLM](https://arxiv.org/abs/2209.03143) and many other ground-breaking papers 

